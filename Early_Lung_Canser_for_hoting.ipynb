{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qA_f_koAQ0Ft"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense,\n",
        "                                    Dropout, BatchNormalization, RandomFlip,\n",
        "                                    RandomRotation, GlobalAveragePooling2D)\n",
        "from tensorflow.keras.applications import ResNet50, DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import (accuracy_score, classification_report,\n",
        "                            confusion_matrix, roc_curve, auc)\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Enable mixed precision training\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "set_global_policy('mixed_float16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBkXeawbQ4Oq",
        "outputId": "ff6771e8-ad26-4eed-f441-1658dec135e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IC21n7MREDp"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/Dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmgZBM7MRT7s",
        "outputId": "e1e23c45-dc77-4e1d-fa63-e8791d71e1ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['IQ-OTH_NCCD lung cancer dataset.txt', 'Bengin', 'Malignant', 'Normal', 'best_ResNet50.keras', 'best_DenseNet121.keras', 'best_EnhancedCNN.keras']\n"
          ]
        }
      ],
      "source": [
        "print (os.listdir(DATASET_PATH))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tm53AA4oRV5U"
      },
      "outputs": [],
      "source": [
        "CLASSES = [\"Bengin\", \"Malignant\", \"Normal\"]\n",
        "CLASS_LABELS = {cls: i for i, cls in enumerate(CLASSES)}\n",
        "IMG_SIZE = (64, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAmBCS8xh06J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLv_dKZlRYaY"
      },
      "outputs": [],
      "source": [
        "# Image loading function\n",
        "def load_images(dataset_path, img_size):\n",
        "    images, labels = [], []\n",
        "    for category in CLASSES:\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "        for img_name in os.listdir(category_path):\n",
        "            img_path = os.path.join(category_path, img_name)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is not None:\n",
        "                img_resized = cv2.resize(img, img_size) / 255.0\n",
        "                images.append(img_resized)\n",
        "                labels.append(CLASS_LABELS[category])\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opBt6FRYRw4t"
      },
      "outputs": [],
      "source": [
        "# Image loading function\n",
        "def load_images(dataset_path, img_size):\n",
        "    images, labels = [], []\n",
        "    for category in CLASSES:\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "        for img_name in os.listdir(category_path):\n",
        "            img_path = os.path.join(category_path, img_name)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is not None:\n",
        "                img_resized = cv2.resize(img, img_size) / 255.0\n",
        "                images.append(img_resized)\n",
        "                labels.append(CLASS_LABELS[category])\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Li7COwaGRztk"
      },
      "outputs": [],
      "source": [
        "X, y = load_images(DATASET_PATH, IMG_SIZE)\n",
        "X = np.expand_dims(X, axis=-1)\n",
        "X = np.repeat(X, 3, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8vOJqJmR4dE"
      },
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                   random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFpvj1csgm1s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuOrZCTmR4at"
      },
      "outputs": [],
      "source": [
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(\n",
        "    X_train.reshape(X_train.shape[0], -1), y_train)\n",
        "X_train_resampled = X_train_resampled.reshape(-1, IMG_SIZE[0], IMG_SIZE[1], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GvEpDqyR4X9"
      },
      "outputs": [],
      "source": [
        "# Convert labels\n",
        "y_train_resampled = to_categorical(y_train_resampled, num_classes=len(CLASSES))\n",
        "y_test = to_categorical(y_test, num_classes=len(CLASSES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk4u7mKijoOR"
      },
      "outputs": [],
      "source": [
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# For validation/test data, we only rescale\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "# Create generators\n",
        "train_generator = train_datagen.flow(\n",
        "    X_train_resampled,\n",
        "    y_train_resampled,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "val_generator = test_datagen.flow(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txzWkv0PR4VI"
      },
      "outputs": [],
      "source": [
        "# Enhanced CNN Model\n",
        "def build_enhanced_cnn():\n",
        "    model = Sequential([\n",
        "        # Data augmentation\n",
        "        RandomFlip(\"horizontal\"),\n",
        "        RandomRotation(0.1),\n",
        "\n",
        "        # Feature extraction\n",
        "        Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2,2),\n",
        "        Conv2D(64, (3,3), activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        MaxPooling2D(2,2),\n",
        "        Conv2D(64, (3,3), activation='relu'),\n",
        "\n",
        "        # Classification\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(128, activation='relu', kernel_regularizer='l2'),\n",
        "        Dropout(0.5),\n",
        "        Dense(len(CLASSES), activation='softmax', dtype='float32')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(0.0001),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kJEFqGmR4Sa"
      },
      "outputs": [],
      "source": [
        "# Transfer Learning Model\n",
        "def create_transfer_model(base_model):\n",
        "    # Freeze base model layers\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    predictions = Dense(len(CLASSES), activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer=Adam(1e-4),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Mcfb79UR4Pl",
        "outputId": "ae9626ff-ba6a-4cbe-c3d1-2a9b87a28b20"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Initialize models\n",
        "resnet = create_transfer_model(ResNet50(weights='imagenet', include_top=False, input_shape=(64,64,3)))\n",
        "densenet = create_transfer_model(DenseNet121(weights='imagenet', include_top=False, input_shape=(64,64,3)))\n",
        "enhanced_cnn = build_enhanced_cnn()\n",
        "\n",
        "models = [resnet, densenet, enhanced_cnn]\n",
        "model_names = ['ResNet50', 'DenseNet121', 'EnhancedCNN']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRm9j3Zqn9Ms"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Improved plotting function that handles both History objects and dictionaries\n",
        "def plot_training(history, name):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Handle both History objects and raw dictionaries\n",
        "    if hasattr(history, 'history'):  # If it's a History object\n",
        "        history_dict = history.history\n",
        "    else:  # If it's already a dictionary\n",
        "        history_dict = history\n",
        "\n",
        "    # Check available metrics\n",
        "    print(f\"\\nAvailable metrics for {name}:\", history_dict.keys())\n",
        "\n",
        "    # Accuracy Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    if 'accuracy' in history_dict:\n",
        "        plt.plot(history_dict['accuracy'], label='Train Accuracy')\n",
        "    if 'val_accuracy' in history_dict:\n",
        "        plt.plot(history_dict['val_accuracy'], label='Val Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(f'{name} - Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    if 'loss' in history_dict:\n",
        "        plt.plot(history_dict['loss'], label='Train Loss')\n",
        "    if 'val_loss' in history_dict:\n",
        "        plt.plot(history_dict['val_loss'], label='Val Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'{name} - Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH4zBrUlR4Jl"
      },
      "outputs": [],
      "source": [
        "# ## Ensemble Learning & Evaluation\n",
        "def ensemble_predict(models, x_input):\n",
        "    predictions = [model.predict(x_input) for model in models]\n",
        "    avg_prediction = np.mean(predictions, axis=0)\n",
        "    return np.argmax(avg_prediction, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zcd3RdYzR4GU",
        "outputId": "f4bc8fef-b230-40c4-eca7-fd97e376569d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 707ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 766ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 208ms/step\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions\n",
        "y_pred_ensemble = ensemble_predict(models, X_test)\n",
        "y_test_labels = np.argmax(y_test, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C03vPUZkR3-E"
      },
      "outputs": [],
      "source": [
        "# Enhanced evaluation metrics\n",
        "def plot_metrics(y_true, y_pred, title):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    # Classification Report\n",
        "    report = classification_report(y_true, y_pred, target_names=CLASSES, output_dict=True)\n",
        "    report_df = pd.DataFrame(report).iloc[:-1, :].T\n",
        "    sns.heatmap(report_df, annot=True, cmap=\"Blues\", ax=axes[0])\n",
        "    axes[0].set_title(f\"{title} - Classification Report\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Oranges\",\n",
        "                xticklabels=CLASSES, yticklabels=CLASSES, ax=axes[1])\n",
        "    axes[1].set_title(f\"{title} - Confusion Matrix\")\n",
        "\n",
        "    # ROC Curve\n",
        "    y_prob = np.mean([model.predict(X_test) for model in models], axis=0)\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob, multi_class=\"ovr\")\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    axes[2].plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "    axes[2].set_title(\"ROC Curve\")\n",
        "    axes[2].legend(loc=\"lower right\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93h4ov469hZ0"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def plot_metrics(y_true, y_pred, model_name=\"Model\", class_names=None):\n",
        "    \"\"\"\n",
        "    Enhanced version that handles multi-class classification\n",
        "\n",
        "    Parameters:\n",
        "    - y_true: True labels (1D array)\n",
        "    - y_pred: Predicted labels (1D array)\n",
        "    - model_name: Name for title\n",
        "    - class_names: List of class names for display\n",
        "    \"\"\"\n",
        "    # Convert to numpy arrays if needed\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # If class_names not provided, use numbers\n",
        "    if class_names is None:\n",
        "        class_names = [f\"Class {i}\" for i in range(len(np.unique(y_true)))]\n",
        "\n",
        "    # Classification report\n",
        "    print(f\"\\nClassification Report for {model_name}:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names,\n",
        "                yticklabels=class_names)\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "# FIRST define your class names (example for 3 classes)\n",
        "class_names = [\"Normal\", \"Benign\", \"Malignant\"]  # Replace with your actual class names\n",
        "\n",
        "# THEN call the function\n",
        "print(\"Ensemble Model Evaluation:\")\n",
        "plot_metrics(y_test_labels, y_pred_ensemble, \"Ensemble Model\", class_names)\n",
        "\n",
        "# Alternative if you don't have names - will auto-generate Class 0, Class 1, etc.\n",
        "# plot_metrics(y_test_labels, y_pred_ensemble, \"Ensemble Model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eps_J2To9-Pd"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from itertools import cycle\n",
        "\n",
        "# 1. First get your predicted probabilities\n",
        "# For Keras/TensorFlow models:\n",
        "y_pred_prob = model.predict(X_test)  # This gives probabilities for each class\n",
        "\n",
        "# For scikit-learn models:\n",
        "# y_pred_prob = model.predict_proba(X_test)\n",
        "\n",
        "# 2. Define your class names (replace with your actual class names)\n",
        "class_names = [\"Class0\", \"Class1\", \"Class2\"]  # Example for 3 classes\n",
        "\n",
        "# 3. The plotting function\n",
        "def plot_multiclass_roc_auc(y_true, y_pred_prob, class_names):\n",
        "    \"\"\"\n",
        "    Plot ROC curves for multi-class classification\n",
        "\n",
        "    Parameters:\n",
        "    y_true: True labels (1D array of class indices)\n",
        "    y_pred_prob: Predicted probabilities (2D array [n_samples, n_classes])\n",
        "    class_names: List of class names\n",
        "    \"\"\"\n",
        "    n_classes = len(class_names)\n",
        "\n",
        "    # Binarize the true labels\n",
        "    y_true_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
        "\n",
        "    # Compute ROC curve and AUC for each class\n",
        "    fpr, tpr, roc_auc = dict(), dict(), dict()\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_prob[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Compute micro-average ROC curve\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_pred_prob.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    # Plot all ROC curves\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    colors = cycle(['blue', 'red', 'green', 'yellow', 'purple'])\n",
        "\n",
        "    for i, color in zip(range(n_classes), colors):\n",
        "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "                 label='{0} (AUC = {1:0.2f})'.format(class_names[i], roc_auc[i]))\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Multi-class ROC Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# 4. Verify your inputs\n",
        "print(\"True labels shape:\", y_test_labels.shape)\n",
        "print(\"Predicted probabilities shape:\", y_pred_prob.shape)\n",
        "print(\"Class names:\", class_names)\n",
        "\n",
        "# 5. Generate the plot\n",
        "plot_multiclass_roc_auc(y_test_labels, y_pred_prob, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxKQvId7UG65"
      },
      "outputs": [],
      "source": [
        "# Generate meta features\n",
        "train_preds = [model.predict(X_train_resampled) for model in models]\n",
        "test_preds = [model.predict(X_test) for model in models]\n",
        "\n",
        "X_train_meta = np.hstack(train_preds)\n",
        "X_test_meta = np.hstack(test_preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3XI8HeoUG3x"
      },
      "outputs": [],
      "source": [
        "# Train meta-model\n",
        "meta_model = LogisticRegression(max_iter=1000)\n",
        "meta_model.fit(X_train_meta, np.argmax(y_train_resampled, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_7HuCYHUG0N"
      },
      "outputs": [],
      "source": [
        "# Evaluate stacking\n",
        "y_pred_stacking = meta_model.predict(X_test_meta)\n",
        "print(\"\\nStacking Model Evaluation:\")\n",
        "plot_metrics(y_test_labels, y_pred_stacking, \"Stacking Model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0Fuz-LUUGwl"
      },
      "outputs": [],
      "source": [
        "# ## Model Interpretation (Grad-CAM)\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
        "    grad_model = Model(\n",
        "        inputs=model.input,\n",
        "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        pred_index = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, pred_index]\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    return heatmap / np.max(heatmap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4hnmGJiUGsM"
      },
      "outputs": [],
      "source": [
        "# Visualization function\n",
        "def visualize_gradcam(model, image, last_conv_layer_name):\n",
        "    heatmap = make_gradcam_heatmap(np.expand_dims(image, 0), model, last_conv_layer_name)\n",
        "    plt.matshow(heatmap)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGmk49W_9Acp"
      },
      "outputs": [],
      "source": [
        "def visualize_gradcam(model, img_array, layer_name, alpha=0.4):\n",
        "    \"\"\"Visualize GradCAM heatmap for a given model and layer\"\"\"\n",
        "\n",
        "    # 1. Preprocess the image\n",
        "    if len(img_array.shape) == 3:\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_tensor = tf.convert_to_tensor(img_array)\n",
        "\n",
        "    # 2. Create gradient model\n",
        "    grad_model = Model(\n",
        "        inputs=[model.inputs],\n",
        "        outputs=[model.get_layer(layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # 3. Compute gradients\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_tensor)\n",
        "        class_idx = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, class_idx]\n",
        "\n",
        "    # 4. Get gradients and generate heatmap\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # 5. Process heatmap\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    heatmap = heatmap.numpy()\n",
        "\n",
        "    # 6. Resize heatmap to match image\n",
        "    heatmap = tf.image.resize(\n",
        "        heatmap[..., tf.newaxis],\n",
        "        (img_array.shape[1], img_array.shape[2])\n",
        "    ).numpy().squeeze()\n",
        "\n",
        "    # 7. Display results\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Original image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img_array[0])  # Remove batch dimension\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Heatmap\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(heatmap, cmap='viridis')\n",
        "    plt.title(\"GradCAM Heatmap\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # Overlay\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(img_array[0])\n",
        "    plt.imshow(heatmap, cmap='viridis', alpha=alpha)\n",
        "    plt.title(\"GradCAM Overlay\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "sample_image = X_test[0]  # Ensure this is a single image with shape (H, W, C)\n",
        "visualize_gradcam(resnet, sample_image, \"conv5_block3_out\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6DtIZcvUTc0"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy_comparison(models, model_names, X_test, y_test):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for model, name in zip(models, model_names):\n",
        "        y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "        acc = accuracy_score(y_test_labels, y_pred)\n",
        "        plt.bar(name, acc, alpha=0.6)\n",
        "    plt.title(\"Model Accuracy Comparison\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.show()\n",
        "\n",
        "plot_accuracy_comparison(models, model_names, X_test, y_test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "jj-DYX_VUGjV",
        "outputId": "5694ef20-eddf-4b65-f2b8-f3c90818f7a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "ü©∫ LUNG CANCER CLASSIFICATION SYSTEM\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'CLASSES' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-99374346.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ü©∫ LUNG CANCER CLASSIFICATION SYSTEM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Available classes: {CLASSES}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CLASSES' is not defined"
          ]
        }
      ],
      "source": [
        "# ## Corrected Interactive Prediction with Working Grad-CAM and Automatic Best Model Selection\n",
        "def predict_single_image():\n",
        "    # Load models with error handling\n",
        "    try:\n",
        "        models = {\n",
        "            'ResNet50': tf.keras.models.load_model(\"/content/drive/MyDrive/Dataset/best_ResNet50.keras\"),\n",
        "            'DenseNet121': tf.keras.models.load_model(\"/content/drive/MyDrive/Dataset/best_DenseNet121.keras\"),\n",
        "            'EnhancedCNN': tf.keras.models.load_model(\"/content/drive/MyDrive/Dataset/best_EnhancedCNN.keras\")\n",
        "        }\n",
        "        # Model performance metrics from your training\n",
        "        model_performance = {\n",
        "            'ResNet50': {'val_acc': 43.23, 'color': 'blue'},\n",
        "            'DenseNet121': {'val_acc': 71.35, 'color': 'red'},\n",
        "            'EnhancedCNN': {'val_acc': 66.67, 'color': 'green'}\n",
        "        }\n",
        "        best_model_name = max(model_performance.items(), key=lambda x: x[1]['val_acc'])[0]\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading models: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # Get image path\n",
        "    while True:\n",
        "        image_path = input(\"\\nüìÅ Enter CT scan image path (or 'q' to quit): \").strip()\n",
        "        if image_path.lower() == 'q':\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            # Read and validate image\n",
        "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                raise ValueError(\"Invalid image or path\")\n",
        "\n",
        "            # Preprocessing pipeline\n",
        "            img_resized = cv2.resize(img, IMG_SIZE)\n",
        "            img_normalized = img_resized / 255.0\n",
        "            img_3channel = np.repeat(img_normalized[..., np.newaxis], 3, axis=-1)\n",
        "            img_input = np.expand_dims(img_3channel, axis=0)\n",
        "\n",
        "            # Get predictions from all models\n",
        "            preds = {name: model.predict(img_input, verbose=0)[0] for name, model in models.items()}\n",
        "\n",
        "            # Get best model prediction\n",
        "            best_pred = preds[best_model_name]\n",
        "            best_pred_class = CLASSES[np.argmax(best_pred)]\n",
        "            best_confidence = np.max(best_pred) * 100\n",
        "\n",
        "            # Calculate ensemble prediction (average of all models)\n",
        "            avg_pred = np.mean(list(preds.values()), axis=0)\n",
        "            ensemble_class = CLASSES[np.argmax(avg_pred)]\n",
        "            ensemble_confidence = np.max(avg_pred) * 100\n",
        "\n",
        "            # Create visualization figure\n",
        "            plt.figure(figsize=(20, 8))\n",
        "\n",
        "            # 1. Original Image\n",
        "            plt.subplot(2, 3, 1)\n",
        "            plt.imshow(img_resized, cmap='gray')\n",
        "            plt.title(f\"Original CT Scan\\n{os.path.basename(image_path)}\", pad=20)\n",
        "            plt.axis('off')\n",
        "\n",
        "            # 2. Grad-CAM Heatmap from Best Model\n",
        "            plt.subplot(2, 3, 2)\n",
        "            try:\n",
        "                # Generate heatmap using best model\n",
        "                layer_name = \"conv5_block3_out\" if best_model_name == \"ResNet50\" else \"conv5_block3_3_conv\" if best_model_name == \"DenseNet121\" else \"conv2d_3\"\n",
        "                heatmap = make_gradcam_heatmap(img_input, models[best_model_name], layer_name)\n",
        "\n",
        "                # Resize heatmap to match original image\n",
        "                heatmap = cv2.resize(heatmap, (img_resized.shape[1], img_resized.shape[0]))\n",
        "\n",
        "                # Display overlay\n",
        "                plt.imshow(img_resized, cmap='gray')\n",
        "                plt.imshow(heatmap, cmap='jet', alpha=0.5)\n",
        "                plt.title(f\"Attention Heatmap ({best_model_name})\", pad=20)\n",
        "                plt.colorbar(label='Attention Intensity')\n",
        "                plt.axis('off')\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Heatmap generation failed: {str(e)}\")\n",
        "                plt.clf()\n",
        "                plt.text(0.5, 0.5, \"Heatmap Unavailable\", ha='center', va='center')\n",
        "                plt.axis('off')\n",
        "\n",
        "            # 3. Best Model Prediction\n",
        "            plt.subplot(2, 3, 3)\n",
        "            colors = ['#4CAF50' if i == np.argmax(best_pred) else '#607D8B' for i in range(len(CLASSES))]\n",
        "            bars = plt.barh(CLASSES, best_pred * 100, color=colors)\n",
        "            plt.bar_label(bars, fmt='%.2f%%', padding=5)\n",
        "            plt.xlim(0, 100)\n",
        "            plt.title(f\"Best Model ({best_model_name})\\nPrediction: {best_pred_class}\\nConfidence: {best_confidence:.2f}%\", pad=20)\n",
        "            plt.xlabel(\"Confidence (%)\")\n",
        "            plt.grid(axis='x', alpha=0.3)\n",
        "\n",
        "            # 4. Ensemble Prediction\n",
        "            plt.subplot(2, 3, 4)\n",
        "            colors = ['#4CAF50' if i == np.argmax(avg_pred) else '#607D8B' for i in range(len(CLASSES))]\n",
        "            bars = plt.barh(CLASSES, avg_pred * 100, color=colors)\n",
        "            plt.bar_label(bars, fmt='%.2f%%', padding=5)\n",
        "            plt.xlim(0, 100)\n",
        "            plt.title(f\"Ensemble Prediction\\nPrediction: {ensemble_class}\\nConfidence: {ensemble_confidence:.2f}%\", pad=20)\n",
        "            plt.xlabel(\"Confidence (%)\")\n",
        "            plt.grid(axis='x', alpha=0.3)\n",
        "\n",
        "            # 5. Model Comparison\n",
        "            plt.subplot(2, 3, 5)\n",
        "            model_names = list(model_performance.keys())\n",
        "            accuracies = [model_performance[name]['val_acc'] for name in model_names]\n",
        "            colors = [model_performance[name]['color'] for name in model_names]\n",
        "\n",
        "            # Highlight best model\n",
        "            for i, name in enumerate(model_names):\n",
        "                if name == best_model_name:\n",
        "                    plt.bar(i, accuracies[i], color=colors[i], edgecolor='gold', linewidth=3)\n",
        "                else:\n",
        "                    plt.bar(i, accuracies[i], color=colors[i])\n",
        "\n",
        "            plt.xticks(range(len(model_names)), model_names)\n",
        "            plt.ylabel(\"Validation Accuracy (%)\")\n",
        "            plt.title(\"Model Performance Comparison\", pad=20)\n",
        "            plt.ylim(0, 100)\n",
        "            plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            return\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {str(e)}\")\n",
        "\n",
        "# Run the interface\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ü©∫ LUNG CANCER CLASSIFICATION SYSTEM\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Available classes: {CLASSES}\\n\")\n",
        "\n",
        "while True:\n",
        "    predict_single_image()\n",
        "    cont = input(\"\\nüîç Analyze another image? (y/n): \").lower()\n",
        "    if cont != 'y':\n",
        "        print(\"üëã Exiting system...\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgFu82MKkv8b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}